{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Classification of an American Sign Language Dataset\n",
    "In this section, we will perform the data preparation, model creation, and model training steps we observed in the last section using a different dataset: images of hands making letters in American Sign Language.\n",
    "\n",
    "Objectives\n",
    "Prepare image data for training\n",
    "Create and compile a simple model for image classification\n",
    "Train an image classification model and observe the results\n",
    "American Sign Language Dataset\n",
    "The American Sign Language alphabet contains 26 letters. Two of those letters (j and z) require movement, so they are not included in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle\n",
    "This dataset is available from the website Kaggle, which is a fantastic place to find datasets and other deep learning resources. In addition to providing resources like datasets and \"kernels\" that are like these notebooks, Kaggle hosts competitions that you can take part in, competing with others in training highly accurate models.\n",
    "\n",
    "If you're looking to practice or see examples of many deep learning projects, Kaggle is a great site to visit.\n",
    "\n",
    "Loading the Data\n",
    "This dataset is not available via Keras in the same way that MNIST is, so let's learn how to load custom data. By the end of this section we will have x_train, y_train, x_valid, and y_valid variables as before.\n",
    "\n",
    "Reading in the Data\n",
    "The sign language dataset is in CSV (Comma Separated Values) format, the same data structure behind Microsoft Excel and Google Sheets. It is a grid of rows and columns with labels at the top, as seen in the train and valid datasets (they may take a moment to load).\n",
    "\n",
    "To load and work with the data, we'll be using a library called Pandas, which is a highly performant tool for loading and manipulating data. We'll read the CSV files into a format called a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a read_csv method that expects a csv file, and returns a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"data/asl_data/sign_mnist_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the DataÂ¶\n",
    "Let's take a look at our data. We can use the head method to print the first few rows of the DataFrame. Each row is an image which has a label column, and also, 784 values representing each pixel value in the image, just like with the MNIST dataset. Note that the labels currently are numerical values, not letters of the alphabet:"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
